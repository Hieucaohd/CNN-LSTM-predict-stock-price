{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# sys.path.append(\"../train_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-15 07:10:57.626650: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-15 07:10:57.648904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-15 07:10:57.687111: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-15 07:10:57.700072: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-15 07:10:57.734675: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-15 07:10:58.659553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from utils.common_train_utils import *\n",
    "from utils.draw_candle_image import *\n",
    "from utils.evaluate_old_models import *\n",
    "from functools import partial\n",
    "# from attention_model import CNNAttention\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateTool1(EvaluateTool):\n",
    "    def do_before_load_model(self, parent_model_path):\n",
    "        pass\n",
    "    \n",
    "    def load_model_and_transform_function(self, parent_model_path, model_path, config_file_path):\n",
    "        self.is_load_before = False\n",
    "        try:\n",
    "            sys.path.append(f\"{parent_model_path}\")\n",
    "            from model_code import CNNAttention\n",
    "            self.is_load_before = True\n",
    "            model_loaded: keras.Sequential = keras.models.load_model(model_path, custom_objects={\"CNNAttention\": CNNAttention})\n",
    "        except Exception as err:\n",
    "            print(f\"Error: {err}\")\n",
    "            model_loaded: keras.Sequential = keras.models.load_model(model_path)\n",
    "        \n",
    "        transform_function = self.get_origin_transform_function(config_file_path)\n",
    "        return model_loaded, transform_function\n",
    "    \n",
    "    \n",
    "    def do_after_load_model(self, parent_model_path):\n",
    "        if self.is_load_before:\n",
    "            sys.path.pop()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss_of_all_models_in_dataset_folder(folder_object):\n",
    "    dataset_path = folder_object.path\n",
    "    \n",
    "    config = read_config(dataset_path)\n",
    "    candle_type_and_directory_save: dict = config[\"candle_type_and_directory_save\"]\n",
    "    days_result = config[\"days_result\"]\n",
    "    \n",
    "    dataset_test = load_dataset_of_each_type_and_combine(f\"{dataset_path}/test\", candle_type_and_directory_save)\n",
    "    \n",
    "    batch_size = random.randint(1, int(len(dataset_test) / 4))\n",
    "    shuffle_buffer = random.randint(1, int(len(dataset_test) / 3))\n",
    "    \n",
    "    dataset_test_1 = dataset_test.shuffle(shuffle_buffer)\n",
    "    dataset_test_2 = dataset_test_1.batch(batch_size)\n",
    "    \n",
    "    # Ví dụ\n",
    "    all_models_folder_path = os.path.join(os.path.abspath(dataset_path), \"model_save\")\n",
    "    evaluate_tool = EvaluateTool1()\n",
    "    \n",
    "    df = evaluate_tool.evaluate_all_models_in_dataset_folder(\n",
    "        all_models_folder_path, \n",
    "        dataset_test_2,\n",
    "        days_result\n",
    "    )\n",
    "    \n",
    "    # print(f\"----------------- {folder_name} -----------------\")\n",
    "    # print(df)\n",
    "    \n",
    "    df[\"total_records\"] = len(dataset_test)\n",
    "    df[\"batch_size\"] = batch_size\n",
    "    df[\"shuffle_buffer\"] = shuffle_buffer\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parent_folder = os.path.abspath(\"../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_symbol = input(\"symbol = (null is all folder)\").lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734246662.453326   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.579509   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.579569   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.583366   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.583440   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.583457   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.807735   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1734246662.807853   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-15 07:11:02.807863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1734246662.807916   87681 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-15 07:11:02.807941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5632 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-12-15 07:11:06.514890: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "W0000 00:00:1734246666.593868   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.606744   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.607845   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.612439   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.614172   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.616042   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.617755   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.619183   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.620543   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.652776   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.655906   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.657767   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.659462   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.671447   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.674598   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.676944   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.678794   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.685053   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.689915   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.692657   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.694594   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.697707   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.699540   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.702712   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.704735   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.713184   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.725395   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.727973   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.735237   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.737455   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.741734   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1734246666.744581   87859 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.7784 - mae: 1.2809 - mse: 3.7784\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 4.0372 - mae: 1.3160 - mse: 4.0372\n"
     ]
    }
   ],
   "source": [
    "all_dfs = {}\n",
    "for f in os.scandir(dataset_parent_folder):\n",
    "    if not f.is_dir(): continue\n",
    "    if just_symbol and f.name != f\"{just_symbol}_with_three_image_ema_macd\": continue\n",
    "    \n",
    "    df = print_loss_of_all_models_in_dataset_folder(f)\n",
    "    all_dfs[f.name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['btc_with_three_image_ema_macd']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btc_with_three_image_ema_macd\n",
      "+---+-------------------------+--------------------+--------------------+---------------+------------+----------------+\n",
      "|   |       model_name        |        mse         |        mae         | total_records | batch_size | shuffle_buffer |\n",
      "+---+-------------------------+--------------------+--------------------+---------------+------------+----------------+\n",
      "| 0 |  cnn_attention_epoch_2  | 5.5311102867126465 | 1.465242862701416  |      64       |     4      |       10       |\n",
      "| 1 | cnn_attention_epoch_2_0 | 5.582462310791016  | 1.4571666717529297 |      64       |     4      |       10       |\n",
      "+---+-------------------------+--------------------+--------------------+---------------+------------+----------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in all_dfs:\n",
    "    print(dataset_name)\n",
    "    print(tabulate(all_dfs[dataset_name], headers='keys', tablefmt='pretty'))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channels_to_time_step_attention_ema_macd_trend_1_1           | 0.9698517322540283 | 0.7524821758270264 |      67       |     9      |       13       |\n",
    "# # | 7  |      channels_to_time_step_attention_ema_macd_trend_1_1_1_1_1_1_1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
