{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common_train_utils import *\n",
    "from utils.draw_candle_image import *\n",
    "from utils.evaluate_old_models import *\n",
    "from functools import partial\n",
    "import os\n",
    "from tabulate import tabulate\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss_of_all_models_in_dataset_folder(folder_object):\n",
    "    dataset_path = folder_object.path\n",
    "    \n",
    "    config = read_config(dataset_path)\n",
    "    candle_type_and_directory_save: dict = config[\"candle_type_and_directory_save\"]\n",
    "    days_result = config[\"days_result\"]\n",
    "    \n",
    "    dataset_test = load_dataset_of_each_type_and_combine(f\"{dataset_path}/test\", candle_type_and_directory_save)\n",
    "    \n",
    "    batch_size = random.randint(1, int(len(dataset_test) / 4))\n",
    "    shuffle_buffer = random.randint(1, int(len(dataset_test) / 3))\n",
    "    \n",
    "    dataset_test_1 = dataset_test.shuffle(shuffle_buffer)\n",
    "    dataset_test_2 = dataset_test_1.batch(batch_size)\n",
    "    \n",
    "    # Ví dụ\n",
    "    all_models_folder_path = os.path.join(os.path.abspath(dataset_path), \"model_save\")\n",
    "    df = evaluate_all_models_in_dataset_folder(\n",
    "        all_models_folder_path, \n",
    "        dataset_test_2,\n",
    "        days_result\n",
    "    )\n",
    "    \n",
    "    # print(f\"----------------- {folder_name} -----------------\")\n",
    "    # print(df)\n",
    "    \n",
    "    df[\"total_records\"] = len(dataset_test)\n",
    "    df[\"batch_size\"] = batch_size\n",
    "    df[\"shuffle_buffer\"] = shuffle_buffer\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_parent_folder = os.path.abspath(\"../dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_symbol = input(\"symbol = (null is all folder)\").lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 3.8054 - mae: 1.4274 - mse: 3.8054 \n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 3.6769 - mae: 1.3582 - mse: 3.6769\n"
     ]
    }
   ],
   "source": [
    "all_dfs = {}\n",
    "for f in os.scandir(dataset_parent_folder):\n",
    "    if not f.is_dir(): continue\n",
    "    if just_symbol and f.name != f\"{just_symbol}_with_ema_macd_trend\": continue\n",
    "    \n",
    "    df = print_loss_of_all_models_in_dataset_folder(f)\n",
    "    all_dfs[f.name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['btc_with_ema_macd_trend']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btc_with_ema_macd_trend\n",
      "+---+------------------------------------------------+-------------------+--------------------+---------------+------------+----------------+\n",
      "|   |                   model_name                   |        mse        |        mae         | total_records | batch_size | shuffle_buffer |\n",
      "+---+------------------------------------------------+-------------------+--------------------+---------------+------------+----------------+\n",
      "| 1 |   model_5_biLSTM_ema_macd_trend_1_1_1_1_1_1    | 4.741568565368652 | 1.4428256750106812 |      62       |     3      |       13       |\n",
      "| 0 | channels_to_time_step_attention_ema_macd_trend | 4.880600929260254 | 1.523748517036438  |      62       |     3      |       13       |\n",
      "+---+------------------------------------------------+-------------------+--------------------+---------------+------------+----------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset_name in all_dfs:\n",
    "    print(dataset_name)\n",
    "    print(tabulate(all_dfs[dataset_name], headers='keys', tablefmt='pretty'))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
