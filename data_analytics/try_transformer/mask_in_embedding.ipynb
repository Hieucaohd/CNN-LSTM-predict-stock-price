{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding output:\n",
      " tf.Tensor(\n",
      "[[[ 0.00588411  0.03575898  0.02621868 -0.00163871]\n",
      "  [ 0.03707338 -0.0178108  -0.02469549  0.0007063 ]\n",
      "  [-0.03425833  0.04134751 -0.02473924 -0.03756804]]\n",
      "\n",
      " [[ 0.04286656 -0.00566039  0.02738074  0.04398335]\n",
      "  [-0.03425833  0.04134751 -0.02473924 -0.03756804]\n",
      "  [-0.03425833  0.04134751 -0.02473924 -0.03756804]]], shape=(2, 3, 4), dtype=float32)\n",
      "Mask:\n",
      " tf.Tensor(\n",
      "[[ True  True False]\n",
      " [ True False False]], shape=(2, 3), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Tạo lớp Embedding với mask_zero=True\n",
    "embedding = tf.keras.layers.Embedding(input_dim=10, output_dim=4, mask_zero=True)\n",
    "\n",
    "# Chuỗi đầu vào có padding\n",
    "x = tf.constant([[1, 2, 0], [4, 0, 0]])  # 0 là padding\n",
    "\n",
    "# Lấy đầu ra từ lớp Embedding\n",
    "y = embedding(x)\n",
    "\n",
    "# Lấy mask tự động tạo bởi lớp Embedding\n",
    "mask = embedding.compute_mask(x)\n",
    "\n",
    "print(\"Embedding output:\\n\", y)\n",
    "print(\"Mask:\\n\", mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1000, size=(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, text_processor, units):\n",
    "    super(Encoder, self).__init__()\n",
    "    self.text_processor = text_processor\n",
    "    self.vocab_size = text_processor.vocabulary_size()\n",
    "    self.units = units\n",
    "    \n",
    "    # The embedding layer converts tokens to vectors\n",
    "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
    "                                               mask_zero=True) # (batch_size, sequence_length=number_word, units)\n",
    "\n",
    "    # The RNN layer processes those vectors sequentially.\n",
    "    self.rnn = tf.keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=tf.keras.layers.GRU(units,\n",
    "                            # Return the sequence and state\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform')) # (batch_size, sequence_length=number_word, units)\n",
    "\n",
    "  def call(self, x):\n",
    "    shape_checker = ShapeChecker()\n",
    "    shape_checker(x, 'batch s')\n",
    "\n",
    "    # number_word = x.shape[1]\n",
    "    # 2. The embedding layer looks up the embedding vector for each token.\n",
    "    x = self.embedding(x) # (batch_size, sequence_length=number_word, units)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 3. The GRU processes the sequence of embeddings.1\n",
    "    x = self.rnn(x) # (batch_size, sequence_length=number_word, units)\n",
    "    shape_checker(x, 'batch s units')\n",
    "\n",
    "    # 4. Returns the new sequence of embeddings.\n",
    "    return x\n",
    "\n",
    "  def convert_input(self, texts):\n",
    "    texts = tf.convert_to_tensor(texts)\n",
    "    if len(texts.shape) == 0:\n",
    "      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
    "    context = self.text_processor(texts).to_tensor()\n",
    "    context = self(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 10, 4)\n",
      "(32, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs = np.random.random((32, 10, 8))\n",
    "gru = keras.layers.GRU(4)\n",
    "output = gru(inputs)\n",
    "output.shape\n",
    "\n",
    "gru = keras.layers.GRU(4, return_sequences=True, return_state=True)\n",
    "whole_sequence_output, final_state = gru(inputs)\n",
    "print(whole_sequence_output.shape)\n",
    "\n",
    "print(final_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 4), dtype=float32, numpy=\n",
       "array([[-2.50189692e-01, -1.42646313e-01, -2.04883680e-01,\n",
       "         2.17535898e-01],\n",
       "       [-5.22055998e-02,  3.63209128e-01, -1.01059161e-01,\n",
       "        -2.96064526e-01],\n",
       "       [-2.86225230e-01, -4.47082594e-02, -3.88183057e-01,\n",
       "         1.52176365e-01],\n",
       "       [-1.98580295e-01, -1.53331250e-01, -3.66241395e-01,\n",
       "        -5.94613180e-02],\n",
       "       [-7.92350471e-02,  1.17571697e-01, -1.73683777e-01,\n",
       "        -7.91808888e-02],\n",
       "       [-3.83977324e-01,  3.76549006e-01, -6.63885325e-02,\n",
       "        -1.36582270e-01],\n",
       "       [-1.15106180e-01,  8.73840451e-02, -3.21828425e-01,\n",
       "        -2.57591426e-01],\n",
       "       [-3.01236719e-01, -3.44546884e-02, -2.71671891e-01,\n",
       "         4.44086455e-02],\n",
       "       [ 2.60451213e-02,  1.97499618e-01, -2.33257830e-01,\n",
       "        -2.57448584e-01],\n",
       "       [-4.18493971e-02, -5.08257188e-02, -2.87322909e-01,\n",
       "         1.80913582e-01],\n",
       "       [-3.65964115e-01,  1.50516391e-01, -3.20583999e-01,\n",
       "        -1.31729782e-01],\n",
       "       [-3.09436917e-01,  3.00828934e-01, -2.16908514e-01,\n",
       "        -1.58768922e-01],\n",
       "       [-2.29305953e-01,  4.90287356e-02, -3.51223558e-01,\n",
       "        -3.91266383e-02],\n",
       "       [-1.54984921e-01, -5.60531467e-02, -3.79005253e-01,\n",
       "        -7.59312809e-02],\n",
       "       [-3.10782909e-01,  8.22089389e-02, -3.66451561e-01,\n",
       "        -3.82216692e-01],\n",
       "       [-3.35990250e-01, -1.27211213e-02, -3.43815565e-01,\n",
       "         1.22166820e-01],\n",
       "       [-1.82566553e-01, -1.43771321e-02, -3.36058497e-01,\n",
       "         5.29571027e-02],\n",
       "       [-3.33931595e-01, -5.85687608e-02, -2.73336381e-01,\n",
       "         3.70778143e-04],\n",
       "       [-3.85851204e-01, -1.39310241e-01, -3.43029141e-01,\n",
       "         2.56192654e-01],\n",
       "       [-2.58220404e-01, -1.79273307e-01, -4.66204822e-01,\n",
       "        -4.22815010e-02],\n",
       "       [-1.48187101e-01,  3.06122810e-01, -2.60281771e-01,\n",
       "        -2.56629065e-02],\n",
       "       [-2.16813818e-01,  2.34997287e-01, -2.65599489e-01,\n",
       "        -2.16872111e-01],\n",
       "       [-1.77337468e-01,  1.33621886e-01, -2.57786572e-01,\n",
       "        -1.94997832e-01],\n",
       "       [-3.65999877e-01,  1.82301670e-01, -1.69930995e-01,\n",
       "         9.18078721e-02],\n",
       "       [-3.01686555e-01,  1.46996483e-01, -2.96399534e-01,\n",
       "        -1.30900875e-01],\n",
       "       [-5.68427682e-01,  3.89922559e-02, -3.46811801e-01,\n",
       "        -7.27532879e-02],\n",
       "       [-5.77033579e-01,  6.77399188e-02, -4.21371639e-01,\n",
       "        -3.96184511e-02],\n",
       "       [-2.66793966e-01,  1.35311946e-01, -3.64129543e-01,\n",
       "        -1.22277841e-01],\n",
       "       [-1.34921372e-01,  6.96312785e-02, -9.33729038e-02,\n",
       "         2.06271514e-01],\n",
       "       [-4.89347696e-01,  1.72589451e-01, -3.48068893e-01,\n",
       "        -3.07505429e-01],\n",
       "       [-4.62139904e-01,  1.12033606e-01, -2.56095588e-01,\n",
       "         2.30245069e-01],\n",
       "       [ 1.27833068e-01,  3.66639644e-02, -1.40378952e-01,\n",
       "        -7.72087499e-02]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_sequence_output.numpy()[0, 9, :] == final_state.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = keras.layers.Bidirectional(\n",
    "        merge_mode='sum',\n",
    "        layer=keras.layers.GRU(4,\n",
    "                            return_sequences=True,\n",
    "                            recurrent_initializer='glorot_uniform', return_state=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_sequence_output, *final_state = a(inputs, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 10, 4])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_sequence_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuỗi đầu tiên\n",
    "gru1 = keras.layers.GRU(units=4, return_sequences=True, return_state=True)\n",
    "whole_sequence_output1, final_state1 = gru1(inputs)\n",
    "\n",
    "# Chuỗi thứ hai (sử dụng trạng thái của GRU1 làm trạng thái khởi tạo)\n",
    "gru2 = keras.layers.GRU(units=4, return_sequences=True, return_state=True)\n",
    "whole_sequence_output2, final_state2 = gru2(inputs, initial_state=final_state1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuỗi Bidirectional đầu tiên\n",
    "bi_gru1 = keras.layers.Bidirectional(\n",
    "    keras.layers.GRU(units=4, return_sequences=True, return_state=True),\n",
    "    merge_mode='sum'\n",
    ")\n",
    "\n",
    "whole_sequence_output1, final_state_fwd1, final_state_bwd1 = bi_gru1(inputs)\n",
    "\n",
    "# Chuỗi Bidirectional thứ hai (sử dụng trạng thái của chuỗi trước)\n",
    "bi_gru2 = keras.layers.Bidirectional(\n",
    "    keras.layers.GRU(units=4, return_sequences=True, return_state=True),\n",
    "    merge_mode='sum'\n",
    ")\n",
    "\n",
    "# Truyền trạng thái từ chuỗi trước\n",
    "whole_sequence_output2, final_state_fwd2, final_state_bwd2 = bi_gru2(\n",
    "    inputs,\n",
    "    initial_state=[final_state_fwd1, final_state_bwd1]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (64, 10, 512)\n",
      "Attention scores shape: (64, 8, 10, 15)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Đầu vào\n",
    "query = tf.random.normal(shape=(64, 10, 512))  # (batch_size, query_length, d_model)\n",
    "key = tf.random.normal(shape=(64, 15, 512))   # (batch_size, key_length, d_model)\n",
    "value = tf.random.normal(shape=(64, 15, 512)) # (batch_size, value_length, d_model)\n",
    "\n",
    "# Multi-Head Attention\n",
    "mha = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)\n",
    "output, attention_scores = mha(query=query, value=value, key=key, return_attention_scores=True)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # (64, 10, 512)\n",
    "print(\"Attention scores shape:\", attention_scores.shape)  # (64, 8, 10, 15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
